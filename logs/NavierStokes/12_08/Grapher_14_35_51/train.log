2024-12-08 14:35:51 INFO     Saving logs in: ./logs/NavierStokes/12_08/Grapher_14_35_51
2024-12-08 14:35:51 INFO     Loading NavierStokes dataset
2024-12-08 14:35:53 INFO     Loading data costs  2.35s
2024-12-08 14:35:53 INFO     Building models
2024-12-08 14:35:55 INFO     Model: Grapher(
  (in_mlp): MLP(
    (processor): Sequential(
      (0): Linear(in_features=3, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=128, bias=True)
    )
  )
  (blocks): ModuleList(
    (0-2): 3 x MultiscaleGraphBlock(
      (phy_aggr): PhysicsGraphBlock(
        (softmax): Softmax(dim=-1)
        (dropout): Dropout(p=0.0, inplace=False)
        (l_in): Linear(in_features=128, out_features=1024, bias=True)
        (l_token): Linear(in_features=128, out_features=1024, bias=True)
        (l_phy): Linear(in_features=128, out_features=32, bias=True)
        (q): Linear(in_features=128, out_features=128, bias=False)
        (k): Linear(in_features=128, out_features=128, bias=False)
        (v): Linear(in_features=128, out_features=128, bias=False)
        (l_out): Linear(in_features=1024, out_features=128, bias=True)
        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (ffn): MLP(
          (processor): Sequential(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): ReLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): ReLU()
            (4): Linear(in_features=128, out_features=128, bias=True)
          )
        )
        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (global_aggr): AttentionGraphBlock(
        (graph_conv): GATv2Conv(128, 128, heads=8)
        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (ffn): MLP(
          (processor): Sequential(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): ReLU()
            (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (3): Linear(in_features=128, out_features=128, bias=True)
            (4): ReLU()
            (5): Linear(in_features=128, out_features=128, bias=True)
          )
        )
        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (local_aggr): AttentionGraphBlock(
        (graph_conv): GATv2Conv(128, 128, heads=8)
        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (ffn): MLP(
          (processor): Sequential(
            (0): Linear(in_features=128, out_features=128, bias=True)
            (1): ReLU()
            (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (3): Linear(in_features=128, out_features=128, bias=True)
            (4): ReLU()
            (5): Linear(in_features=128, out_features=128, bias=True)
          )
        )
        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (processor): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): ReLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  (out_mlp): MLP(
    (processor): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=1, bias=True)
    )
  )
)
2024-12-08 14:35:55 INFO     Criterion: <utils.loss.LpLoss object at 0x7f8a10c9d180>
2024-12-08 14:35:55 INFO     Optimizer: AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 1e-05
)
2024-12-08 14:35:55 INFO     Scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7f8a10c9cfa0>
2024-12-08 14:35:55 INFO     Building models costs  1.11s
2024-12-08 14:35:55 INFO     Start training
2024-12-08 14:35:55 INFO     Train dataset size: 9600
2024-12-08 14:35:55 INFO     Valid dataset size: 1200
2024-12-08 14:35:55 INFO     Test dataset size: 1200
2024-12-08 14:41:45 INFO     Epoch 0 | train_loss: 0.26306126 | Time: 350.03s | lr: 0.0010
2024-12-08 14:42:11 INFO     Epoch 0 | valid_loss: 0.21425771 | Time: 26.21s
2024-12-08 14:42:11 INFO     Epoch 0 | save best models in ./logs/NavierStokes/12_08/Grapher_14_35_51
